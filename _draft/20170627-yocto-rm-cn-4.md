### Chapter 4. Technical Details[¶][1862]


This chapter provides technical details for various parts of the Yocto Project. Currently, topics include Yocto Project components, cross-toolchain generation, shared state (sstate) cache, x32, Wayland support, and Licenses.
本章提供了 Yocto 项目不同部分的技术细节。目前，主题都有 Yocto 项目组件，交叉工具链生成，共享状态（sstate）缓存，x32，Wayland 支持，以及授权。

### 4.1. Yocto 项目组件[¶][870]

The [BitBake][4208] task executor together with various types of configuration files form the OpenEmbedded Core. This section overviews these components by describing their use and how they interact.
[BitBake][4208] task 执行者和来自 OpenEmbedd Core 的多种类型的配置文件。本节通过描述它们的用法和如何与它们交互来综述这些模块。

BitBake handles the parsing and execution of the data files. The data itself is of various types:
BitBake 掌控了解析和执行这些数据文件。这些数据文件本身有很多类型：

*   _Recipes:_  Provides details about particular pieces of software.
*	_Recipes:_	提供软件的特殊部分的细节。

*   _Class Data:_  Abstracts common build information (e.g. how to build a Linux kernel).
*	_Class Data:_  抽象通用构建信息（比如，如何构建一个 Linux 内核）。

*   _Configuration Data:_  Defines machine-specific settings, policy decisions, and so forth. Configuration data acts as the glue to bind everything together.
*	_Configuration Data:_  定义了机器相关的配置，策略决策，等等。配置数据扮演了将所有东西绑定到一起的粘合剂的角色。

BitBake knows how to combine multiple data sources together and refers to each data source as a layer. For information on layers, see the "[Understanding and Creating Layers][4209]" section of the Yocto Project Development Manual.
BitBake 知道如何将多个数据源组合起来，并且引用全部数据作为 layer。关于 layer 的信息参见 Yocto 项目开发手册的 "[Un derstanding and Creating Layers][4209]" 一节。

Following are some brief details on these core components. For additional information on how these components interact during a build, see the "[A Closer Look at the Yocto Project Development Environment][4210]" Chapter.
剩下的是和心模块的简要详情。额外的关于在构建过程中，这些组件如何交互的信息参见"[A Closer Look at the Yocto Project Development Environment][4210]" 一章。

### 4.1.1. BitBake[¶][447]

BitBake is the tool at the heart of the OpenEmbedded build system and is responsible for parsing the [Metadata][3831], generating a list of tasks from it, and then executing those tasks.
BitBake 工具是 OpenEmbedded 构建系统的核心，负责解析 [Metadata][3831]，从中得到一组 task，然后执行这些 task。

This section briefly introduces BitBake. If you want more information on BitBake, see the [BitBake User Manual][3832].
本节简单的介绍 BitBake。如果你想要更多关于 BitBake 的信息，参见 [BitBake User Manual][3832]。

To see a list of the options BitBake supports, use either of the following commands:
要看 BitBake 支持的选项的列表，使用下面任一命令：

```
     $ bitbake -h
     $ bitbake --help

```

The most common usage for BitBake is `bitbake  _`packagename`_` , where `packagename` is the name of the package you want to build (referred to as the "target" in this manual). The target often equates to the first part of a recipe's filename (e.g. "foo" for a recipe named `foo_1.3.0-r0.bb`). So, to process the `matchbox-desktop_1.2.3.bb` recipe file, you might type the following:
BitBake 最常见的用法是 `bitbake  _`packagename`_`，其中 `packagename` 是你想要构建的软件包的名字（参考手册中的 “target”）。这个目标通常等同于 recipe 文件名的第一部分（比如， "foo" 就是一个 recipe 名称 `foo_1.3.0-r0.bb`）。所以，要处理 `matchbox-desktop_1.2.3.bb` recipe 文件，你肯呢过要输入下面的命令：


```
     $ bitbake matchbox-desktop

```

Several different versions of `matchbox-desktop` might exist. BitBake chooses the one selected by the distribution configuration. You can get more details about how BitBake chooses between different target versions and providers in the "[Preferences][3833]" section of the BitBake User Manual.
可能存在几个不同版本的 `matchbox-desktop`。 BitBake 根据发行版配置选择版本。你可以在 BitBake 用户手册的 "[Preferences][3833]" 一节获得更多关于 BitBake 如何在不同的目标版本和供应者之间挑选版本的细节。

BitBake also tries to execute any dependent tasks first. So for example, before building `matchbox-desktop`, BitBake would build a cross compiler and `glibc` if they had not already been built.
BitBake 同样也尝试在构建 `matchbox-desktop`之前，首先执行任何独立的 task，BitBake 将会构建一个交叉编译器和 `glibc` ，如果这些还没有构建。

A useful BitBake option to consider is the `-k` or `--continue` option. This option instructs BitBake to try and continue processing the job as long as possible even after encountering an error. When an error occurs, the target that failed and those that depend on it cannot be remade. However, when you use this option other dependencies can still be processed.
BitBake 一个有用的选项可以认为是 `-k` 或 `--continue`。这个选项会命令 BitBake 尝试和继续处理尽量执行工作，只要有可能的话，甚至是遇到一个错误。当错误发生时，目标失败了，依赖于它的工作没办法继续。然而当你使用这个选项一塔依赖可以继续处理。

### 4.1.2. 元数据 (Recipes)[¶][448]

Files that have the `.bb` suffix are "recipes" files. In general, a recipe contains information about a single piece of software. This information includes the location from which to download the unaltered source, any source patches to be applied to that source (if needed), which special configuration options to apply, how to compile the source files, and how to package the compiled output.
后缀是 `.bb` 的文件是 “recipe” 文件。通常来说，一个 recipe 包含一个单独软件的信息。这些信息包括从哪里下载未被更改的源文件，如何编译源文件，以及如何打包这些编译输出。

The term "package" is sometimes used to refer to recipes. However, since the word "package" is used for the packaged output from the OpenEmbedded build system (i.e. `.ipk` or `.deb` files), this document avoids using the term "package" when referring to recipes.
术语 `package` 是用来代指 recipe 的东西。然后，既然单词 `package` 用来打包 OpenEmbedded 构建系统（比如，`.ipk` 或 `.deb` 文件），当前文档避免在代指 recipe 时使用名词 “package”。

### 4.1.3. Classes[¶][449]

Class files (`.bbclass`) contain information that is useful to share between [Metadata][3834] files. An example is the [`autotools`][3835] class, which contains common settings for any application that Autotools uses. The "[Classes][3836]" chapter provides details about classes and how to use them.
class 文件（“.bbclass`）包含对 [Metadata][3834] 文件之间的共享很有用的信息。一个例子是 [`autotools`][3835] class，包含了任何使用 Autotool 的应用程序的通用配置。"[Classes][3836]" 一节提供了详细的关于 class 和如何使用它们的细节。

### 4.1.4. Configuration[¶][450]

The configuration files (`.conf`) define various configuration variables that govern the OpenEmbedded build process. These files fall into several areas that define machine configuration options, distribution configuration options, compiler tuning options, general common configuration options, and user configuration options in `local.conf`, which is found in the [Build Directory][3837].
配置文件（`.conf`）定义了多种控制 OpenEmbedded 构建过程的配置变量。在的这些文件这些文件覆盖了几个区域：定义机器配置选项，发行版配置选项，编译器调优选项，通用配置选项，和 [Build Directory][3837] 中 `local.conf` 里定义的用户配置选项。

### 4.2. Cross-Development Toolchain Generation[¶][871]

The Yocto Project does most of the work for you when it comes to creating [cross-development toolchains][4211]. This section provides some technical background on how cross-development toolchains are created and used. For more information on toolchains, you can also see the [Yocto Project Software Development Kit (SDK) Developer's Guide][4212].
在创建 [cross-development toolchains][4211] 时，Yocto 项目为你做了大部分工作。本节提供了一些关于交叉开发工具链如何被创建和使用的技术背景。更多关于工具链的信息，你可以浏览 [Yocto Project Software Development Kit (SDK) Developer's Guide][4212]。

In the Yocto Project development environment, cross-development toolchains are used to build the image and applications that run on the target hardware. With just a few commands, the OpenEmbedded build system creates these necessary toolchains for you.
在 Yocto 项目开发环境中，交叉开发工具链通常用于构建目标运行在镜像上的镜像和应用程序。通过很少的几个命令，OpenEmbedded 构建系统就可以为你创建了必要的工具链。

The following figure shows a high-level build environment regarding toolchain construction and use.
下卖弄的表格展示了一个高层次的关于工具链构成和使用的构建环境。

![](https://www.yoctoproject.org/docs/current/ref-manual/figures/cross-development-toolchains.png)

Most of the work occurs on the Build Host. This is the machine used to build images and generally work within the the Yocto Project environment. When you run BitBake to create an image, the OpenEmbedded build system uses the host `gcc` compiler to bootstrap a cross-compiler named `gcc-cross`. The `gcc-cross` compiler is what BitBake uses to compile source files when creating the target image. You can think of `gcc-cross` simply as an automatically generated cross-compiler that is used internally within BitBake only.
大部分的工作都发生在构建主机上。这个机器用来使用 Yocto 项目环境构建镜像和普通工作。当你运行 BitBake 创建镜像， OpenEmbedded 构建系统使用主机的 `gcc` 编译器来自举一个名为 `gcc-cross` 的交叉编译器。这个 `gcc-cross` 编译器就是 BitBake 在创建镜像时用来编译源代码的。你可以认为 `gcc-cross` 仅仅是一个自动生成的，仅仅在 BitBake 内部使用的交叉编译器。

### Note

The extensible SDK does not use `gcc-cross-canadian` since this SDK ships a copy of the OpenEmbedded build system and the sysroot within it contains `gcc-cross`.
可扩展的 SDK 不使用 `gcc-cross-canadian` ，因为这个 SDK 传送了一份 OpenEmbedded 构建系统的拷贝，而且里面的 sysroot 包含了 `gcc-cross`。

The chain of events that occurs when `gcc-cross` is bootstrapped is as follows:
当 `gcc-cross` 被引导起来的时候，发生的事件链如下所示：

```
     gcc -> binutils-cross -> gcc-cross-initial -> linux-libc-headers -> glibc-initial -> glibc -> gcc-cross -> gcc-runtime

```

*   `gcc`: The build host's GNU Compiler Collection (GCC).
*   `gcc`: 构建主机的 GNU 编译器集合。

*   `binutils-cross`: The bare minimum binary utilities needed in order to run the `gcc-cross-initial` phase of the bootstrap operation.
*   `binutils-cross`: 引导阶段操作的运行 `gcc-cross-initial` 阶段需要的裸的最小的二进制工具集。

*   `gcc-cross-initial`: An early stage of the bootstrap process for creating the cross-compiler. This stage builds enough of the `gcc-cross`, the C library, and other pieces needed to finish building the final cross-compiler in later stages. This tool is a "native" package (i.e. it is designed to run on the build host).
*   `gcc-cross-initial`: 引导处理过程中，创建交叉编译器的的早期阶段。这个阶段构建足够了 `gcc-cross` ，包括 C 库，以及其他需要用来完成构建最终交叉编译器的东西。

*   `linux-libc-headers`: Headers needed for the cross-compiler.
*   `linux-libc-headers`: 交叉编译器需要的头文件。

*   `glibc-initial`: An initial version of the Embedded GLIBC needed to bootstrap `glibc`.
*   `glibc-initial`: 需要用来引导 `glibc` 的嵌入式 GLIBC 的初始版本。

*   `gcc-cross`: The final stage of the bootstrap process for the cross-compiler. This stage results in the actual cross-compiler that BitBake uses when it builds an image for a targeted device.
*   `gcc-cross` 构建交叉编译器的引导阶段的最终阶段。这个阶段的结果是实际的交叉编译器，BitBake 在构建目标设备的镜像时要用到这个编译器。

    ### Note

    If you are replacing this cross compiler toolchain with a custom version, you must replace `gcc-cross`.
    如果你使用自定义版本的编译器替换这个交叉编译器，你必须替换 `gcc-cross`。

    This tool is also a "native" package (i.e. it is designed to run on the build host).
    这个工具是个本地的软件包（也就是说它是设计运行在构建主机上的）。

*   `gcc-runtime`: Runtime libraries resulting from the toolchain bootstrapping process. This tool produces a binary that consists of the runtime libraries need for the targeted device.
*   `gcc-runtime`: 工具链引导过程的产出的运行时库文件。这个工具产生了一个包含目标设备需要的运行时库的二进制文件。

You can use the OpenEmbedded build system to build an installer for the relocatable SDK used to develop applications. When you run the installer, it installs the toolchain, which contains the development tools (e.g., the `gcc-cross-canadian`), `binutils-cross-canadian`, and other `nativesdk-*`tools, which are tools native to the SDK (i.e. native to [`SDK_ARCH`][4213]), you need to cross-compile and test your software. The figure shows the commands you use to easily build out this toolchain. This cross-development toolchain is built to execute on the [`SDKMACHINE`][4214], which might or might not be the same machine as the Build Host.
你可以使用 OpenEmbedded 构建系统来构建一个用来开发应用程序的可重定位的 SDK 的安装包。当你运行这个安装包，它
会安装包含开发工具（例如，`gcc-cross-canadian`），`binutils-cross-canadian`和其它 `nativesdk-*` 工具的工具链，这些工具都是本地 SDK（即，本地 [`SDK_ARCH`][4213]），你需要交叉编译和测试你的软件。这个表格展示了你可以用来轻松构建这个工具链的命令。构建这个交叉开发工具链是用来在 [`SDKMACHINE`][4214] 上执行，和构建主机可能一样也可能不一样。

### Note

If your target architecture is supported by the Yocto Project, you can take advantage of pre-built images that ship with the Yocto Project and already contain cross-development toolchain installers.
如果你的目标架构被 Yocto 项目支持，你可以利用 Yocto 项目附带的构件好的镜像和已经包含了交叉开发工具链的安装包。

Here is the bootstrap process for the relocatable toolchain:
这里是可重定位的工具链的引导过程：

```
     gcc -> binutils-crosssdk -> gcc-crosssdk-initial -> linux-libc-headers ->
        glibc-initial -> nativesdk-glibc -> gcc-crosssdk -> gcc-cross-canadian

```

*   `gcc`: The build host's GNU Compiler Collection (GCC).
*   `gcc`: 构建主机的 GNU 编译器集合。

*   `binutils-crosssdk`: The bare minimum binary utilities needed in order to run the `gcc-crosssdk-initial` phase of the bootstrap operation.
*   `binutils-crosssdk`: 引导阶段操作的运行 `gcc-crosssdk-initial` 阶段需要的裸的最小的二进制工具集。

*   `gcc-crosssdk-initial`: An early stage of the bootstrap process for creating the cross-compiler. This stage builds enough of the `gcc-crosssdk` and supporting pieces so that the final stage of the bootstrap process can produce the finished cross-compiler. This tool is a "native" binary that runs on the build host.
*   `gcc-crosssdk-initial`: 引导处理过程中，创建交叉编译器的的早期阶段。这个阶段构建足够了 `gcc-crosssdk` 和支持片段，这样引导过程的最终阶段就可以产生完成的交叉编译器。这个工具是一个可以运行在构建主机上的本地二进制文件。

*   `linux-libc-headers`: Headers needed for the cross-compiler.
*   `linux-libc-headers`: 交叉编译器需要的头文件。

*   `glibc-initial`: An initial version of the Embedded GLIBC needed to bootstrap `nativesdk-glibc`.
*   `glibc-initial`: 需要用来引导 `nativesdk-glibc` 的嵌入式 GLIBC 的初始版本。

*   `nativesdk-glibc`: The Embedded GLIBC needed to bootstrap the `gcc-crosssdk`.
*   `nativesdk-glibc`: 需要用来引导 `gcc-crosssdk` 的嵌入式 GLIBC。

*   `gcc-crosssdk`: The final stage of the bootstrap process for the relocatable cross-compiler. The `gcc-crosssdk` is a transitory compiler and never leaves the build host. Its purpose is to help in the bootstrap process to create the eventual relocatable `gcc-cross-canadian` compiler, which is relocatable. This tool is also a "native" package (i.e. it is designed to run on the build host).

*   `gcc-cross-canadian`: The final relocatable cross-compiler. When run on the [`SDKMACHINE`][1863], this tool produces executable code that runs on the target device. Only one cross-canadian compiler is produced per architecture since they can be targeted at different processor optimizations using configurations passed to the compiler through the compile commands. This circumvents the need for multiple compilers and thus reduces the size of the toolchains.
*   `gcc-cross-canadian`: 最终可重定位的交叉编译器。当运行在 [`SDKMACHINE`][1863] 上时，这个工具制造了可以运行在目标设备上的可执行带阿妈。每种架构只会生成一个 cross-canadian 编译器，因为通过使用传给编译命令的配置可以针对不同的处理器进行优化。这规避了多个编译器的需求，也因此减少了工具链的体积。

### Note

For information on advantages gained when building a cross-development toolchain installer, see the "[Building an SDK Installer][4215]" section in the Yocto Project Software Development Kit (SDK) Developer's Guide.
更多关于构建交叉开发工具链安装包的高级经验参见 Yocto Project Software Development Kit (SDK) Developer's Guide 的 "[Building an SDK Installer][4215]" 一节。

### 4.3. 共享状态缓存[¶][872]

By design, the OpenEmbedded build system builds everything from scratch unless BitBake can determine that parts do not need to be rebuilt. Fundamentally, building from scratch is attractive as it means all parts are built fresh and there is no possibility of stale data causing problems. When developers hit problems, they typically default back to building from scratch so they know the state of things from the start.
通过设计， OpenEmbedded 构建系统从头开始构建所有东西，除非 BitBake 能确定哪些部分不需要重新构建。根本上，从头开始构建很吸引人，因为这意味着所有东西都是新鲜构建的，不可能有陈旧的东西产生问题。当开发者发现问题，通常默认退回到从头开始构建，这样他们就能从开始知道东西的状态。

Building an image from scratch is both an advantage and a disadvantage to the process. As mentioned in the previous paragraph, building from scratch ensures that everything is current and starts from a known state. However, building from scratch also takes much longer as it generally means rebuilding things that do not necessarily need to be rebuilt.
从头开始构建镜像是一个既有利由又有弊的过程。如上一段落提到的，从头构建可以保证所有东西都是现在的，而且是从一个可知的状态开始的。但是，从头构建也会花费更多的时间，因为通常这意味着重要新构建一些不必要的东西。

The Yocto Project implements shared state code that supports incremental builds. The implementation of the shared state code answers the following questions that were fundamental roadblocks within the OpenEmbedded incremental build support system:
Yocto 项目实现了支持增量构建的共享状态代码。共享状态代码的实现回答了下面 OpenEmbedded 增量构建支持系统的基础障碍的问题：

*   What pieces of the system have changed and what pieces have not changed?
*   系统的哪些部分已经变了，而那些又没有改变？

*   How are changed pieces of software removed and replaced?
*   变化了的软件的部分是如何被删除和替代的？

*   How are pre-built components that do not need to be rebuilt from scratch used when they are available?
*   不需要重新从头构建的构件好的组件在可用的时候是怎么处理的？

For the first question, the build system detects changes in the "inputs" to a given task by creating a checksum (or signature) of the task's inputs. If the checksum changes, the system assumes the inputs have changed and the task needs to be rerun. For the second question, the shared state (sstate) code tracks which tasks add which output to the build process. This means the output from a given task can be removed, upgraded or otherwise manipulated. The third question is partly addressed by the solution for the second question assuming the build system can fetch the sstate objects from remote locations and install them if they are deemed to be valid.
对于第一个问题，构建系统通过为 task 的输入创建校验和，然后检查这个输入校验和。如果校验和改变了，系统就认为输入已经改变了，task 就需要重新运行。对于第二个问题，共享状态（sstate）代码跟踪那个 task 添加了那些输出到构建过程。这意味着给定 task 的输出可以被删除，升级或者其他操作。第三个问题被第二个问题的方案部分解决了，假设构建系统能从远处获取 sstate 对象，并且如果它们看起来是有效的，就安装它们。

### Note

The OpenEmbedded build system does not maintain [`PR`][4216] information as part of the shared state packages. Consequently, considerations exist that affect maintaining shared state feeds. For information on how the OpenEmbedded build system works with packages and can track incrementing `PR` information, see the "[Automatically Incrementing a Binary Package Revision Number][4217]" section.OpenEmbedded 构建系统不会把 [`PR`][4216] 信息当做共享状态包的一部分维护。所以存在影响维护共享状态订阅源的注意事项。关于 OpenEmbedded 构建系统和软件包合作，已经跟尊增长的 `PR` 信息，参见 "[Automatically Incrementing a Binary Package Revision Number][4217]"。

The rest of this section goes into detail about the overall incremental build architecture, the checksums (signatures), shared state, and some tips and tricks.
本节剩下部分进入整个增量构建架构的细节，校验和（签名），共享状态，以及其他技巧和窍门。

### 4.3.1. 总体架构[¶][451]

When determining what parts of the system need to be built, BitBake works on a per-task basis rather than a per-recipe basis. You might wonder why using a per-task basis is preferred over a per-recipe basis. To help explain, consider having the IPK packaging backend enabled and then switching to DEB. In this case, the [`do_install`][3838] and [`do_package`][3839] task outputs are still valid. However, with a per-recipe approach, the build would not include the`.deb` files. Consequently, you would have to invalidate the whole build and rerun it. Rerunning everything is not the best solution. Also, in this case, the core must be "taught" much about specific tasks. This methodology does not scale well and does not allow users to easily add new tasks in layers or as external recipes without touching the packaged-staging core.
当确定要构建系统的那些部分时， BitBake 工作在每个 task 的基础，而不是每个 recipe 的基础。你可能会疑问为什么使用每个 task 的基础会优先于每个 recipe 的基础。要帮助解释这个，考虑下已使能了 IPK 打包后端，然后要切换到 DEB。这种情况下，[`do_install`][3838] 和 [`do_package`][3839] task 的输出仍然是有效的。然而，使用每个 recipe 的方法，构建将不包括 `.deb` 文件。所以你将必须无效整个构建并重新运行。重新运行不是最好的解决办法。同样的，这种情况下，核心必须要被教导更多关于指定 task 的信息。这个方法论不会扩展的很好，也不允许用户轻易的在 layer 中添加新的 task 或者作为外部 recipe 而不接触打包阶段的核心。

### 4.3.2. 校验和 (签名)[¶][452]

The shared state code uses a checksum, which is a unique signature of a task's inputs, to determine if a task needs to be run again. Because it is a change in a task's inputs that triggers a rerun, the process needs to detect all the inputs to a given task. For shell tasks, this turns out to be fairly easy because the build process generates a "run" shell script for each task and it is possible to create a checksum that gives you a good idea of when the task's data changes.
共享状态代码使用校验和，每个 task 的输入都有一个唯一的签名，来确定一个 task 是否需要再次运行。因为是一个 task 的输入变化了才出发重新运行，这个过程需要探测一个给定 task 的全部输入。对于 shell task，这就会变得非常容易，因为构建过程为每个 task 生成一个 “运行” shell 脚本，而且能创建校验和给你了一个好办法来判断 task 的数据变化了。

To complicate the problem, there are things that should not be included in the checksum. First, there is the actual specific build path of a given task - the [`WORKDIR`][3840]. It does not matter if the work directory changes because it should not affect the output for target packages. Also, the build process has the objective of making native or cross packages relocatable.
复杂化这个问题，有些东西不应该被包含进校验和。第一，每个人都有一个实际指定的构建路径 - [`WORKDIR`][3840]。如果工作目录变化不会有影响，因为它不应该影响目标软件包的输出。同样，构建过程有责任让本地或交叉软件包可重定位。

### Note

Both native and cross packages run on the build host. However, cross packages generate output for the target architecture.
本地和交叉的软件包都运行在构建主机上。然而交叉包生成给目标架构的输出。

The checksum therefore needs to exclude `WORKDIR`. The simplistic approach for excluding the work directory is to set `WORKDIR` to some fixed value and create the checksum for the "run" script.
这个校验和因此需要排除 `WORKDIR`。排除工作目录的简单途径是设置 `WORKDIR` 为一些固定的值，为 “运行”脚本创建校验和。

Another problem results from the "run" scripts containing functions that might or might not get called. The incremental build solution contains code that figures out dependencies between shell functions. This code is used to prune the "run" scripts down to the minimum set, thereby alleviating this problem and making the "run" scripts much more readable as a bonus.
另一个问题源于 “运行”脚本包含了可能或不可能被调用的函数。增量构建解决方案包含能找出依赖 shell 函数间的依赖的代码。这些代码用来删除 “运行”脚本到最小集合，从而缓解这个问题，额外的好处是使得“运行”脚本可读性更好。

So far we have solutions for shell scripts. What about Python tasks? The same approach applies even though these tasks are more difficult. The process needs to figure out what variables a Python function accesses and what functions it calls. Again, the incremental build solution contains code that first figures out the variable and function dependencies, and then creates a checksum for the data used as the input to the task.
到目前为止，我们有了shell脚本的解决方案。那 Python task 呢？方法相同，及时这些 task 更困难。这个过程需要找出 Python 函数访问了那些变量，以及调用了哪些函数。再次，增量构建方案包含了找出变量和函数依赖的代码，然后为这些作为 task 的输入的数据创造一个校验和。

Like the `WORKDIR` case, situations exist where dependencies should be ignored. For these cases, you can instruct the build process to ignore a dependency by using a line like the following:
像 `WORKDIR` 的例子，情况存在需要忽略的依赖处。在这些情况下，你可以使用下面的命令让构建过程忽略依赖：

```
     PACKAGE_ARCHS[vardepsexclude] = "MACHINE"

```

This example ensures that the [`PACKAGE_ARCHS`][3841] variable does not depend on the value of [`MACHINE`][3842], even if it does reference it.
这个例子保证变量 [`PACKAGE_ARCHS`][3841] 不依赖于 [`MACHINE`][3842] 的值，及时它的确要参考这个值。

Equally, there are cases where we need to add dependencies BitBake is not able to find. You can accomplish this by using a line like the following:
相同的，有时我们也要添加 BitBake 不能找到的依赖。你可以通过使用下面的命令完成这个：

```
      PACKAGE_ARCHS[vardeps] = "MACHINE"

```

This example explicitly adds the `MACHINE` variable as a dependency for `PACKAGE_ARCHS`.
这个例子显式的添加变量 `MACHINE` 为 `PACKAGE_ARCHS` 的依赖。

Consider a case with in-line Python, for example, where BitBake is not able to figure out dependencies. When running in debug mode (i.e. using `-DDD`), BitBake produces output when it discovers something for which it cannot figure out dependencies. The Yocto Project team has currently not managed to cover those dependencies in detail and is aware of the need to fix this situation.
考虑下 in-line Python 这种情况，举个例子，哪里 BitBake 不能够找到依赖。当运行在调试模式（即，使用 `-DDD`）， BitBake 当发现某些他无法找出依赖时会产生输出。 Yocto 项目组已经目前不计划详细覆盖这些依赖，但也意识到了需要修改这些情景。

Thus far, this section has limited discussion to the direct inputs into a task. Information based on direct inputs is referred to as the "basehash" in the code. However, there is still the question of a task's indirect inputs - the things that were already built and present in the [Build Directory][3843]. The checksum (or signature) for a particular task needs to add the hashes of all the tasks on which the particular task depends. Choosing which dependencies to add is a policy decision. However, the effect is to generate a master checksum that combines the basehash and the hashes of the task's dependencies.
迄今为止，这一章已经有限的讨论了 task 的直接输入。基于直接输入的信息是当做代码中的的 “bashhash”。然而这里还有一个关于 task 的间接输入的问题，这些东西已经构建了并且存在于 [Build Directory][3843] 中。某个特定 task 的校验和（或者签名）需要添加该 task 依赖的全部 task 的哈希值。挑选合适的依赖来添加是一个策略决策。然而，产生的效果是生成了一个包含了基础哈希和 task 的依赖的哈希的主校验和。

At the code level, there are a variety of ways both the basehash and the dependent task hashes can be influenced. Within the BitBake configuration file, we can give BitBake some extra information to help it construct the basehash. The following statement effectively results in a list of global variable dependency excludes - variables never included in any checksum:
在代码级，有各种不同的途径可以既影响 basehash，也影响依赖 task 的哈希。在 BitBake 的配置文件中，我们可以为 BitBake 提供额外的信息帮助他构建 basehash。西买你的语句有效的造成排除了一串全局变量依赖-这些变量不会被包含到任何校验和中。

```
     BB_HASHBASE_WHITELIST ?= "TMPDIR FILE PATH PWD BB_TASKHASH BBPATH DL_DIR \
         SSTATE_DIR THISDIR FILESEXTRAPATHS FILE_DIRNAME HOME LOGNAME SHELL TERM \
         USER FILESPATH STAGING_DIR_HOST STAGING_DIR_TARGET COREBASE PRSERV_HOST \
         PRSERV_DUMPDIR PRSERV_DUMPFILE PRSERV_LOCKDOWN PARALLEL_MAKE \
         CCACHE_DIR EXTERNAL_TOOLCHAIN CCACHE CCACHE_DISABLE LICENSE_PATH SDKPKGSUFFIX"

```

The previous example excludes [`WORKDIR`][3844] since that variable is actually constructed as a path within [`TMPDIR`][3845], which is on the whitelist.
之前的例子排除了 [`WORKDIR`][3844] 因为这个变量实际上被作为 [`TMPDIR`][3845] 路径的一部分，而 `TMPDIR` 是白名单的一部分。

The rules for deciding which hashes of dependent tasks to include through dependency chains are more complex and are generally accomplished with a Python function. The code in `meta/lib/oe/sstatesig.py` shows two examples of this and also illustrates how you can insert your own policy into the system if so desired. This file defines the two basic signature generators `OE-Core` uses: "OEBasic" and "OEBasicHash". By default, there is a dummy "noop" signature handler enabled in BitBake. This means that behavior is unchanged from previous versions. `OE-Core` uses the "OEBasicHash" signature handler by default through this setting in the `bitbake.conf` file:
决通过依赖琏定那些 task 的哈希要被包含进来的规则是更复杂的，而且通常要用一个 Python 函数来完成。`meta/lib/oe/sstatesig.py` 中的代码显示了两个这样的例子，同时也阐明了你如何插入你自己的策略到这个系统，如果你想要的话。这个文件定义了两个 `OE-Core` 使用的基本的签名生成器：“OEBasic” 和 “OEBasicHash“。默认情况下在 BitBake 还使能了一个假的 “noop” 签名处理器。这意味着不会从之前的版本进行变更。 `OE-Core` 默认通过 `bitbake.conf` 文件的设置使用 “OEBasicHash” 签名处理器。

```
     BB_SIGNATURE_HANDLER ?= "OEBasicHash"

```

The "OEBasicHash" `BB_SIGNATURE_HANDLER` is the same as the "OEBasic" version but adds the task hash to the stamp files. This results in any[Metadata][3846] change that changes the task hash, automatically causing the task to be run again. This removes the need to bump [`PR`][3847] values, and changes to Metadata automatically ripple across the build.
“OEBasicHash” `BB_SIGNATURE_HANDLER` 和 “OEBasic” 版本是一样的，但是给时间戳文件添加了 task 哈希。这就造成全部 [Metadata][3846] 变化了之后 task 的哈希也会变化，自动引起 task 重新运行。这就去除了需要碰撞 [`PR`][3847] 的值，改变了元数据自动影响整个构建。

It is also worth noting that the end result of these signature generators is to make some dependency and hash information available to the build. This information includes:
值得注意的是这些签名生成器的最终结果是用来制造依赖和对构建有用的哈希信息。

*   `BB_BASEHASH_task-` _`taskname`_ : The base hashes for each task in the recipe.
*	`BB_BASEHASH_task-` _`taskname`_ : recipe 中每个 task 的基础哈希。

*   `BB_BASEHASH_` _`filename`_ `:` _`taskname`_ : The base hashes for each dependent task.
*	`BB_BASEHASH_` _`filename`_ `:` _`taskname`_ : 每个独立 task 的基础哈希。

*   `BBHASHDEPS_` _`filename`_ `:` _`taskname`_ : The task dependencies for each task.
*	`BBHASHDEPS_` _`filename`_ `:` _`taskname`_ : task 依赖的每个 task。

*   `BB_TASKHASH`: The hash of the currently running task.
*	`BB_TASKHASH`: 当前运行 task 的哈希。

### 4.3.3. 共享状态[¶][453]

Checksums and dependencies, as discussed in the previous section, solve half the problem of supporting a shared state. The other part of the problem is being able to use checksum information during the build and being able to reuse or rebuild specific components.
校验和与依赖关系，如前面章节讨论的，结局了支持共享状态这个问题的一般。问题的另一半是在构建过程中能使用校验和信息以及能够重用或重新构建指定组件。

The [`sstate`][3848] class is a relatively generic implementation of how to "capture" a snapshot of a given task. The idea is that the build process does not care about the source of a task's output. Output could be freshly built or it could be downloaded and unpacked from somewhere - the build process does not need to worry about its origin.
[`sstate`][3848] class 是一个针对如何 “捕捉” 一个特定任务的快照的相对通用的实现。这个想法是构建过程不关心 task 输出的源。输出能新鲜构建或者是可以从某处下载拆包的 - 构建过程不需要担心它的起源。

There are two types of output, one is just about creating a directory in [`WORKDIR`][3849]. A good example is the output of either [`do_install`][3850] or [`do_package`][3851]. The other type of output occurs when a set of data is merged into a shared directory tree such as the sysroot.
有两种类型的输出，一个是差不多在 [`WORKDIR`][3849] 创建一个目录。一个好例子是 [`do_install`][3850] 或 [`do_package`][3851] 的输出。其它类型的输出发生在当一组数据被合并到一个共享目录树，比如 sysroot。

The Yocto Project team has tried to keep the details of the implementation hidden in `sstate` class. From a user's perspective, adding shared state wrapping to a task is as simple as this [`do_deploy`][3852] example taken from the [`deploy`][3853] class:
Yocto 项目组已经尝试保存隐藏在 `sstate` classe 的实现的细节。从用户角度来看，给一个任务添加共享状态封装和  [`do_deploy`][3852] 例子中接收 [`deploy`][3853] class 一样简单：

```
     DEPLOYDIR = "${WORKDIR}/deploy-${PN}"
     SSTATETASKS += "do_deploy"
     do_deploy[sstate-inputdirs] = "${DEPLOYDIR}"
     do_deploy[sstate-outputdirs] = "${DEPLOY_DIR_IMAGE}"

     python do_deploy_setscene () {
         sstate_setscene(d)
     }
     addtask do_deploy_setscene
     do_deploy[dirs] = "${DEPLOYDIR} ${B}"

```

The following list explains the previous example:
下面的列表解释了前面的例子：

*   Adding "do_deploy" to `SSTATETASKS` adds some required sstate-related processing, which is implemented in the [`sstate`][873] class, to before and after the [`do_deploy`][874] task.
*	添加 "do_deploy" 到 `SSTATETASKS`，在 [`do_deploy`][874] task 之前和之后，增加了有些和共享状态相关的处理，这些是在 [`sstate`][873] class 中实现的。

*   The `do_deploy[sstate-inputdirs] = "${DEPLOYDIR}"` declares that `do_deploy` places its output in `${DEPLOYDIR}` when run normally (i.e. when not using the sstate cache). This output becomes the input to the shared state cache.
*	`do_deploy[sstate-inputdirs] = "${DEPLOYDIR}"` 声明在普通运行时（即，在不使用共享状态缓存时）， `do_deploy` 把他的输出放到 `${DEPLOYDIR}`。这些输出变成了共享状态缓存的输入。

*   The `do_deploy[sstate-outputdirs] = "${DEPLOY_DIR_IMAGE}"` line causes the contents of the shared state cache to be copied to `${DEPLOY_DIR_IMAGE}`.
*	`do_deploy[sstate-outputdirs] = "${DEPLOY_DIR_IMAGE}"` 一行代码使得共享状态缓存的内容被拷贝到 `${DEPLOY_DIR_IMAGE}`。

    ### Note

    If `do_deploy` is not already in the shared state cache or if its input checksum (signature) has changed from when the output was cached, the task will be run to populate the shared state cache, after which the contents of the shared state cache is copied to`${DEPLOY_DIR_IMAGE}`. If `do_deploy` is in the shared state cache and its signature indicates that the cached output is still valid (i.e. if no relevant task inputs have changed), then the contents of the shared state cache will be copied directly to`${DEPLOY_DIR_IMAGE}` by the `do_deploy_setscene` task instead, skipping the `do_deploy` task.
	如果 `do_deploy` 不是已经存在于共享状态缓存，或者如果它的输入校验和（签名）在输出被缓存后又变化了，这个任务运行产生共享状态缓存，在这之后，共享状态缓存的内容会拷贝到 `${DEPLOY_DIR_IMAGE}` 。如果 `do_deploy` 在共享状态缓存而且它的签名指出缓存的输出依旧有效（即，没有关联的 task 输出发生变化），然后共享状态缓存的内容将会通过 `do_deploy_setscene` task 被直接拷贝到 `${DEPLOY_DIR_IMAGE}` ，直接跳过 `do_deploy` task。

*   The following task definition is glue logic needed to make the previous settings effective:
*	下面的 task 定义是一个逻辑胶水，需要用来是前面的设置生效：

    ```
         python do_deploy_setscene () {
             sstate_setscene(d)
         }
         addtask do_deploy_setscene

    ```

    `sstate_setscene()` takes the flags above as input and accelerates the `do_deploy` task through the shared state cache if possible. If the task was accelerated, `sstate_setscene()` returns True. Otherwise, it returns False, and the normal `do_deploy` task runs. For more information, see the "[setscene][875]" section in the BitBake User Manual.
	`sstate_setcene()` 获取上面的标志作为输入，如果可能的话通过共享状态缓存加速 `do_deploy` task。如果这个 task 被加速了， `sstate_setscene()` 返回真。否则，它会返回假，然后正常运行 `do_deploy` task。更多信息参见 BitBake User Manual 的 "[setscene][875]" 一节。

*   The `do_deploy[dirs] = "${DEPLOYDIR} ${B}"` line creates `${DEPLOYDIR}` and `${B}` before the `do_deploy` task runs, and also sets the current working directory of `do_deploy` to `${B}`. For more information, see the "[Variable Flags][876]" section in the BitBake User Manual.
* 	`do_deploy[dirs] = "${DEPLOYDIR} ${B}"` 一行代码在 `do_deploy` task 运行之前创建了 `${DEPLOYDIR}` 和 `${B}`，同时也设置了 `do_deploy` 的当前工作目录为 `${B}`。更多信息参见 BitBake User Manual 的 "[Variable Flags][876]" 一节。

    ### Note

    In cases where `sstate-inputdirs` and `sstate-outputdirs` would be the same, you can use `sstate-plaindirs`. For example, to preserve the `${PKGD}` and `${PKGDEST}` output from the [`do_package`][877] task, use the following:
	在 `sstate-inputdirs` 和 `sstate-outputdirs`一样的情况下，你可以用 `sstate-plaindirs`。举个例子，要从 [`do_package`][877] task 下保留 `${PKGD}` 和 `${PKGDEST}` 输出，使用下面的命令：
    ```
         do_package[sstate-plaindirs] = "${PKGD} ${PKGDEST}"

    ```

*   `sstate-inputdirs` and `sstate-outputdirs` can also be used with multiple directories. For example, the following declares `PKGDESTWORK` and`SHLIBWORK` as shared state input directories, which populates the shared state cache, and `PKGDATA_DIR` and `SHLIBSDIR` as the corresponding shared state output directories:
*	`sstate-inputdirs` 和 `sstate-outputdirs` 可以和多个目录使用。举个例子，下面声明了 `PKGDESTWORK` 和 `SHLIBWORK` 作为共享状态输入目录，产生共享状态缓存，和 `PKGDATA_DIR` 和 `SHLIBSDIR`对应的共享状态输出目录：

    ```
         do_package[sstate-inputdirs] = "${PKGDESTWORK} ${SHLIBSWORKDIR}"
         do_package[sstate-outputdirs] = "${PKGDATA_DIR} ${SHLIBSDIR}"

    ```

*   These methods also include the ability to take a lockfile when manipulating shared state directory structures, for cases where file additions or removals are sensitive:
*	这些方法也包含了在操作共享状态目录结构时获取锁文件的能力，举个文件增删敏感的例子：

    ```
         do_package[sstate-lockfile] = "${PACKAGELOCK}"

    ```

Behind the scenes, the shared state code works by looking in [`SSTATE_DIR`][3854] and [`SSTATE_MIRRORS`][3855] for shared state files. Here is an example:
在这些情景之后，共享状态代码通过在 [`SSTATE_DIR`][3854] 和 [`SSTATE_MIRRORS`][3855] 查看共享状态文件工作。下面是个例子：

```
     SSTATE_MIRRORS ?= "\
     file://.* http://someserver.tld/share/sstate/PATH;downloadfilename=PATH \n \
     file://.* file:///some/local/dir/sstate/PATH"

```

### Note

The shared state directory (`SSTATE_DIR`) is organized into two-character subdirectories, where the subdirectory names are based on the first two characters of the hash. If the shared state directory structure for a mirror has the same structure as `SSTATE_DIR`, you must specify "PATH" as part of the URI to enable the build system to map to the appropriate subdirectory.

The shared state package validity can be detected just by looking at the filename since the filename contains the task checksum (or signature) as described earlier in this section. If a valid shared state package is found, the build process downloads it and uses it to accelerate the task.

The build processes use the `*_setscene` tasks for the task acceleration phase. BitBake goes through this phase before the main execution code and tries to accelerate any tasks for which it can find shared state packages. If a shared state package for a task is available, the shared state package is used. This means the task and any tasks on which it is dependent are not executed.

As a real world example, the aim is when building an IPK-based image, only the [`do_package_write_ipk`][3856] tasks would have their shared state packages fetched and extracted. Since the sysroot is not used, it would never get extracted. This is another reason why a task-based approach is preferred over a recipe-based approach, which would have to install the output from every task.

### 4.3.4. Tips and Tricks[¶][454]

The code in the build system that supports incremental builds is not simple code. This section presents some tips and tricks that help you work around issues related to shared state code.

#### 4.3.4.1. Debugging[¶][30]

Seeing what metadata went into creating the input signature of a shared state (sstate) task can be a useful debugging aid. This information is available in signature information (`siginfo`) files in [`SSTATE_DIR`][3467]. For information on how to view and interpret information in `siginfo` files, see the "[Viewing Task Variable Dependencies][3468]" section.

#### 4.3.4.2. Invalidating Shared State[¶][31]

The OpenEmbedded build system uses checksums and shared state cache to avoid unnecessarily rebuilding tasks. Collectively, this scheme is known as "shared state code."

As with all schemes, this one has some drawbacks. It is possible that you could make implicit changes to your code that the checksum calculations do not take into account. These implicit changes affect a task's output but do not trigger the shared state code into rebuilding a recipe. Consider an example during which a tool changes its output. Assume that the output of `rpmdeps` changes. The result of the change should be that all the `package`and `package_write_rpm` shared state cache items become invalid. However, because the change to the output is external to the code and therefore implicit, the associated shared state cache items do not become invalidated. In this case, the build process uses the cached items rather than running the task again. Obviously, these types of implicit changes can cause problems.

To avoid these problems during the build, you need to understand the effects of any changes you make. Realize that changes you make directly to a function are automatically factored into the checksum calculation. Thus, these explicit changes invalidate the associated area of shared state cache. However, you need to be aware of any implicit changes that are not obvious changes to the code and could affect the output of a given task.

When you identify an implicit change, you can easily take steps to invalidate the cache and force the tasks to run. The steps you can take are as simple as changing a function's comments in the source code. For example, to invalidate package shared state files, change the comment statements of [`do_package`][3469] or the comments of one of the functions it calls. Even though the change is purely cosmetic, it causes the checksum to be recalculated and forces the OpenEmbedded build system to run the task again.

### Note

For an example of a commit that makes a cosmetic change to invalidate shared state, see this [commit][3470].

### 4.4. Automatically Added Runtime Dependencies[¶][878]

The OpenEmbedded build system automatically adds common types of runtime dependencies between packages, which means that you do not need to explicitly declare the packages using [`RDEPENDS`][4218]. Three automatic mechanisms exist (`shlibdeps`, `pcdeps`, and `depchains`) that handle shared libraries, package configuration (pkg-config) modules, and `-dev` and `-dbg` packages, respectively. For other types of runtime dependencies, you must manually declare the dependencies.

*   `shlibdeps`: During the [`do_package`][1864] task of each recipe, all shared libraries installed by the recipe are located. For each shared library, the package that contains the shared library is registered as providing the shared library. More specifically, the package is registered as providing the [soname][1865] of the library. The resulting shared-library-to-package mapping is saved globally in [`PKGDATA_DIR`][1866] by the [`do_packagedata`][1867] task.

    Simultaneously, all executables and shared libraries installed by the recipe are inspected to see what shared libraries they link against. For each shared library dependency that is found, `PKGDATA_DIR` is queried to see if some package (likely from a different recipe) contains the shared library. If such a package is found, a runtime dependency is added from the package that depends on the shared library to the package that contains the library.

    The automatically added runtime dependency also includes a version restriction. This version restriction specifies that at least the current version of the package that provides the shared library must be used, as if " _`package`_  (>=  _`version`_ )" had been added to [`RDEPENDS`][1868]. This forces an upgrade of the package containing the shared library when installing the package that depends on the library, if needed.

    If you want to avoid a package being registered as providing a particular shared library (e.g. because the library is for internal use only), then add the library to [`PRIVATE_LIBS`][1869] inside the package's recipe.

*   `pcdeps`: During the [`do_package`][1870] task of each recipe, all pkg-config modules (`*.pc` files) installed by the recipe are located. For each module, the package that contains the module is registered as providing the module. The resulting module-to-package mapping is saved globally in[`PKGDATA_DIR`][1871] by the [`do_packagedata`][1872] task.

    Simultaneously, all pkg-config modules installed by the recipe are inspected to see what other pkg-config modules they depend on. A module is seen as depending on another module if it contains a "Requires:" line that specifies the other module. For each module dependency, `PKGDATA_DIR` is queried to see if some package contains the module. If such a package is found, a runtime dependency is added from the package that depends on the module to the package that contains the module.

    ### Note

    The `pcdeps` mechanism most often infers dependencies between `-dev` packages.

*   `depchains`: If a package `foo` depends on a package `bar`, then `foo-dev` and `foo-dbg` are also made to depend on `bar-dev` and `bar-dbg`, respectively. Taking the `-dev` packages as an example, the `bar-dev` package might provide headers and shared library symlinks needed by `foo-dev`, which shows the need for a dependency between the packages.

    The dependencies added by `depchains` are in the form of [`RRECOMMENDS`][1873].

    ### Note

    By default, `foo-dev` also has an `RDEPENDS`-style dependency on `foo`, because the default value of `RDEPENDS_${PN}-dev` (set in`bitbake.conf`) includes "${PN}".

    To ensure that the dependency chain is never broken, `-dev` and `-dbg` packages are always generated by default, even if the packages turn out to be empty. See the [`ALLOW_EMPTY`][1874] variable for more information.

The `do_package` task depends on the [`do_packagedata`][4219] task of each recipe in [`DEPENDS`][4220] through use of a `[`[`deptask`][4221]`]` declaration, which guarantees that the required shared-library/module-to-package mapping information will be available when needed as long as `DEPENDS` has been correctly set.

### 4.5. Fakeroot and Pseudo[¶][879]

Some tasks are easier to implement when allowed to perform certain operations that are normally reserved for the root user. For example, the[`do_install`][4222] task benefits from being able to set the UID and GID of installed files to arbitrary values.

One approach to allowing tasks to perform root-only operations would be to require BitBake to run as root. However, this method is cumbersome and has security issues. The approach that is actually used is to run tasks that benefit from root privileges in a "fake" root environment. Within this environment, the task and its child processes believe that they are running as the root user, and see an internally consistent view of the filesystem. As long as generating the final output (e.g. a package or an image) does not require root privileges, the fact that some earlier steps ran in a fake root environment does not cause problems.

The capability to run tasks in a fake root environment is known as "fakeroot", which is derived from the BitBake keyword/variable flag that requests a fake root environment for a task. In current versions of the OpenEmbedded build system, the program that implements fakeroot is known as Pseudo.

Pseudo overrides system calls through the `LD_PRELOAD` mechanism to give the illusion of running as root. To keep track of "fake" file ownership and permissions resulting from operations that require root permissions, an sqlite3 database is used. This database is stored in`${`[`WORKDIR`][4223]`}/pseudo/files.db` for individual recipes. Storing the database in a file as opposed to in memory gives persistence between tasks, and even between builds.

### Caution

If you add your own task that manipulates the same files or directories as a fakeroot task, then that task should also run under fakeroot. Otherwise, the task will not be able to run root-only operations, and will not see the fake file ownership and permissions set by the other task. You should also add a dependency on `virtual/fakeroot-native:do_populate_sysroot`, giving the following:
```
       fakeroot do_mytask () {
           ...
       }
       do_mytask[depends] += "virtual/fakeroot-native:do_populate_sysroot"

```

For more information, see the [`FAKEROOT*`][4224] variables in the BitBake User Manual. You can also reference this [Pseudo][4225] article.

### 4.6. x32[¶][880]

x32 is a processor-specific Application Binary Interface (psABI) for x86_64\. An ABI defines the calling conventions between functions in a processing environment. The interface determines what registers are used and what the sizes are for various C data types.

Some processing environments prefer using 32-bit applications even when running on Intel 64-bit platforms. Consider the i386 psABI, which is a very old 32-bit ABI for Intel 64-bit platforms. The i386 psABI does not provide efficient use and access of the Intel 64-bit processor resources, leaving the system underutilized. Now consider the x86_64 psABI. This ABI is newer and uses 64-bits for data sizes and program pointers. The extra bits increase the footprint size of the programs, libraries, and also increases the memory and file system size requirements. Executing under the x32 psABI enables user programs to utilize CPU and system resources more efficiently while keeping the memory footprint of the applications low. Extra bits are used for registers but not for addressing mechanisms.

### 4.6.1. Support[¶][455]

This Yocto Project release supports the final specifications of x32 psABI. Support for x32 psABI exists as follows:

*   You can create packages and images in x32 psABI format on x86_64 architecture targets.

*   You can successfully build many recipes with the x32 toolchain.

*   You can create and boot `core-image-minimal` and `core-image-sato` images.

### 4.6.2. Completing x32[¶][456]

Future Plans for the x32 psABI in the Yocto Project include the following:

*   Enhance and fix the few remaining recipes so they work with and support x32 toolchains.

*   Enhance RPM Package Manager (RPM) support for x32 binaries.

*   Support larger images.

### 4.6.3. Using x32 Right Now[¶][457]

Follow these steps to use the x32 spABI:

*   Enable the x32 psABI tuning file for `x86_64` machines by editing the `conf/local.conf` like this:

    ```
          MACHINE = "qemux86-64"
          DEFAULTTUNE = "x86-64-x32"
          baselib = "${@d.getVar('BASE_LIB_tune-' + (d.getVar('DEFAULTTUNE', True) \
             or 'INVALID'), True) or 'lib'}"
          #MACHINE = "genericx86"
          #DEFAULTTUNE = "core2-64-x32"

    ```

*   As usual, use BitBake to build an image that supports the x32 psABI. Here is an example:

    ```
         $ bitbake core-image-sato

    ```

*   As usual, run your image using QEMU:

    ```
         $ runqemu qemux86-64 core-image-sato

    ```

### 4.7. Wayland[¶][881]

[Wayland][4226] is a computer display server protocol that provides a method for compositing window managers to communicate directly with applications and video hardware and expects them to communicate with input hardware using other libraries. Using Wayland with supporting targets can result in better control over graphics frame rendering than an application might otherwise achieve.

The Yocto Project provides the Wayland protocol libraries and the reference [Weston][4227] compositor as part of its release. This section describes what you need to do to implement Wayland and use the compositor when building an image for a supporting target.

### 4.7.1. Support[¶][458]

The Wayland protocol libraries and the reference Weston compositor ship as integrated packages in the `meta` layer of the [Source Directory][3857]. Specifically, you can find the recipes that build both Wayland and Weston at `meta/recipes-graphics/wayland`.

You can build both the Wayland and Weston packages for use only with targets that accept the [Mesa 3D and Direct Rendering Infrastructure][3858], which is also known as Mesa DRI. This implies that you cannot build and use the packages if your target uses, for example, the Intel® Embedded Media and Graphics Driver (Intel® EMGD) that overrides Mesa DRI.

### Note

Due to lack of EGL support, Weston 1.0.3 will not run directly on the emulated QEMU hardware. However, this version of Weston will run under X emulation without issues.

### 4.7.2. Enabling Wayland in an Image[¶][459]

To enable Wayland, you need to enable it to be built and enable it to be included in the image.

#### 4.7.2.1. Building[¶][32]

To cause Mesa to build the `wayland-egl` platform and Weston to build Wayland with Kernel Mode Setting ([KMS][3471]) support, include the "wayland" flag in the [`DISTRO_FEATURES`][3472] statement in your `local.conf` file:

```
     DISTRO_FEATURES_append = " wayland"

```

### Note

If X11 has been enabled elsewhere, Weston will build Wayland with X11 support

#### 4.7.2.2. Installing[¶][33]

To install the Wayland feature into an image, you must include the following [`CORE_IMAGE_EXTRA_INSTALL`][3473] statement in your `local.conf` file:

```
     CORE_IMAGE_EXTRA_INSTALL += "wayland weston"

```

### 4.7.3. Running Weston[¶][460]

To run Weston inside X11, enabling it as described earlier and building a Sato image is sufficient. If you are running your image under Sato, a Weston Launcher appears in the "Utility" category.

Alternatively, you can run Weston through the command-line interpretor (CLI), which is better suited for development work. To run Weston under the CLI, you need to do the following after your image is built:

1.  Run these commands to export `XDG_RUNTIME_DIR`:

    ```
         mkdir -p /tmp/$USER-weston
         chmod 0700 /tmp/$USER-weston
         export XDG_RUNTIME_DIR=/tmp/$USER-weston

    ```

2.  Launch Weston in the shell:

    ```
         weston

    ```

### 4.8. Licenses[¶][882]

This section describes the mechanism by which the OpenEmbedded build system tracks changes to licensing text. The section also describes how to enable commercially licensed recipes, which by default are disabled.

For information that can help you maintain compliance with various open source licensing during the lifecycle of the product, see the "[Maintaining Open Source License Compliance During Your Project's Lifecycle][4228]" section in the Yocto Project Development Manual.

### 4.8.1. Tracking License Changes[¶][461]

The license of an upstream project might change in the future. In order to prevent these changes going unnoticed, the `[LIC_FILES_CHKSUM][3474]` variable tracks changes to the license text. The checksums are validated at the end of the configure step, and if the checksums do not match, the build will fail.

#### 4.8.1.1. Specifying the `LIC_FILES_CHKSUM` Variable[¶][34]

The `LIC_FILES_CHKSUM` variable contains checksums of the license text in the source code for the recipe. Following is an example of how to specify`LIC_FILES_CHKSUM`:

```
     LIC_FILES_CHKSUM = "file://COPYING;md5=xxxx \
                         file://licfile1.txt;beginline=5;endline=29;md5=yyyy \
                         file://licfile2.txt;endline=50;md5=zzzz \
                         ..."

```

### Notes

*   When using "beginline" and "endline", realize that line numbering begins with one and not zero. Also, the included lines are inclusive (i.e. lines five through and including 29 in the previous example for `licfile1.txt`).

*   When a license check fails, the selected license text is included as part of the QA message. Using this output, you can determine the exact start and finish for the needed license text.

The build system uses the `[S][1875]` variable as the default directory when searching files listed in `LIC_FILES_CHKSUM`. The previous example employs the default directory.

Consider this next example:

```
     LIC_FILES_CHKSUM = "file://src/ls.c;beginline=5;endline=16;\
                                         md5=bb14ed3c4cda583abc85401304b5cd4e"
     LIC_FILES_CHKSUM = "file://${WORKDIR}/license.html;md5=5c94767cedb5d6987c902ac850ded2c6"

```

The first line locates a file in `${S}/src/ls.c` and isolates lines five through 16 as license text. The second line refers to a file in `[WORKDIR][1876]`.

Note that `LIC_FILES_CHKSUM` variable is mandatory for all recipes, unless the `LICENSE` variable is set to "CLOSED".

#### 4.8.1.2. Explanation of Syntax[¶][35]

As mentioned in the previous section, the `LIC_FILES_CHKSUM` variable lists all the important files that contain the license text for the source code. It is possible to specify a checksum for an entire file, or a specific section of a file (specified by beginning and ending line numbers with the "beginline" and "endline" parameters, respectively). The latter is useful for source files with a license notice header, README documents, and so forth. If you do not use the "beginline" parameter, then it is assumed that the text begins on the first line of the file. Similarly, if you do not use the "endline" parameter, it is assumed that the license text ends with the last line of the file.

The "md5" parameter stores the md5 checksum of the license text. If the license text changes in any way as compared to this parameter then a mismatch occurs. This mismatch triggers a build failure and notifies the developer. Notification allows the developer to review and address the license text changes. Also note that if a mismatch occurs during the build, the correct md5 checksum is placed in the build log and can be easily copied to the recipe.

There is no limit to how many files you can specify using the `LIC_FILES_CHKSUM` variable. Generally, however, every project requires a few specifications for license tracking. Many projects have a "COPYING" file that stores the license information for all the source code files. This practice allows you to just track the "COPYING" file as long as it is kept up to date.

### Tip

If you specify an empty or invalid "md5" parameter, BitBake returns an md5 mis-match error and displays the correct "md5" parameter value during the build. The correct parameter is also captured in the build log.

### Tip

If the whole file contains only license text, you do not need to use the "beginline" and "endline" parameters.

### 4.8.2. Enabling Commercially Licensed Recipes[¶][462]

By default, the OpenEmbedded build system disables components that have commercial or other special licensing requirements. Such requirements are defined on a recipe-by-recipe basis through the [`LICENSE_FLAGS`][3859] variable definition in the affected recipe. For instance, the `poky/meta/recipes-multimedia/gstreamer/gst-plugins-ugly` recipe contains the following statement:

```
     LICENSE_FLAGS = "commercial"

```

Here is a slightly more complicated example that contains both an explicit recipe name and version (after variable expansion):

```
     LICENSE_FLAGS = "license_${PN}_${PV}"

```

In order for a component restricted by a `LICENSE_FLAGS` definition to be enabled and included in an image, it needs to have a matching entry in the global [`LICENSE_FLAGS_WHITELIST`][3860] variable, which is a variable typically defined in your `local.conf` file. For example, to enable the `poky/meta/recipes-multimedia/gstreamer/gst-plugins-ugly` package, you could add either the string "commercial_gst-plugins-ugly" or the more general string "commercial" to `LICENSE_FLAGS_WHITELIST`. See the "[License Flag Matching][3861]" section for a full explanation of how `LICENSE_FLAGS`matching works. Here is the example:

```
     LICENSE_FLAGS_WHITELIST = "commercial_gst-plugins-ugly"

```

Likewise, to additionally enable the package built from the recipe containing `LICENSE_FLAGS = "license_${PN}_${PV}"`, and assuming that the actual recipe name was `emgd_1.10.bb`, the following string would enable that package as well as the original `gst-plugins-ugly` package:

```
     LICENSE_FLAGS_WHITELIST = "commercial_gst-plugins-ugly license_emgd_1.10"

```

As a convenience, you do not need to specify the complete license string in the whitelist for every package. You can use an abbreviated form, which consists of just the first portion or portions of the license string before the initial underscore character or characters. A partial string will match any license that contains the given string as the first portion of its license. For example, the following whitelist string will also match both of the packages previously mentioned as well as any other packages that have licenses starting with "commercial" or "license".

```
     LICENSE_FLAGS_WHITELIST = "commercial license"

```

#### 4.8.2.1. License Flag Matching[¶][36]

License flag matching allows you to control what recipes the OpenEmbedded build system includes in the build. Fundamentally, the build system attempts to match [`LICENSE_FLAGS`][3475] strings found in recipes against [`LICENSE_FLAGS_WHITELIST`][3476] strings found in the whitelist. A match causes the build system to include a recipe in the build, while failure to find a match causes the build system to exclude a recipe.

In general, license flag matching is simple. However, understanding some concepts will help you correctly and effectively use matching.

Before a flag defined by a particular recipe is tested against the contents of the whitelist, the expanded string `_${PN}` is appended to the flag. This expansion makes each `LICENSE_FLAGS` value recipe-specific. After expansion, the string is then matched against the whitelist. Thus, specifying`LICENSE_FLAGS = "commercial"` in recipe "foo", for example, results in the string `"commercial_foo"`. And, to create a match, that string must appear in the whitelist.

Judicious use of the `LICENSE_FLAGS` strings and the contents of the `LICENSE_FLAGS_WHITELIST` variable allows you a lot of flexibility for including or excluding recipes based on licensing. For example, you can broaden the matching capabilities by using license flags string subsets in the whitelist.

### Note

When using a string subset, be sure to use the part of the expanded string that precedes the appended underscore character (e.g. `usethispart_1.3`, `usethispart_1.4`, and so forth).

For example, simply specifying the string "commercial" in the whitelist matches any expanded `LICENSE_FLAGS` definition that starts with the string "commercial" such as "commercial_foo" and "commercial_bar", which are the strings the build system automatically generates for hypothetical recipes named "foo" and "bar" assuming those recipes simply specify the following:

```
     LICENSE_FLAGS = "commercial"

```

Thus, you can choose to exhaustively enumerate each license flag in the whitelist and allow only specific recipes into the image, or you can use a string subset that causes a broader range of matches to allow a range of recipes into the image.

This scheme works even if the `LICENSE_FLAGS` string already has `_${PN}` appended. For example, the build system turns the license flag "commercial_1.2_foo" into "commercial_1.2_foo_foo" and would match both the general "commercial" and the specific "commercial_1.2_foo" strings found in the whitelist, as expected.

Here are some other scenarios:

*   You can specify a versioned string in the recipe such as "commercial_foo_1.2" in a "foo" recipe. The build system expands this string to "commercial_foo_1.2_foo". Combine this license flag with a whitelist that has the string "commercial" and you match the flag along with any other flag that starts with the string "commercial".

*   Under the same circumstances, you can use "commercial_foo" in the whitelist and the build system not only matches "commercial_foo_1.2" but also matches any license flag with the string "commercial_foo", regardless of the version.

*   You can be very specific and use both the package and version parts in the whitelist (e.g. "commercial_foo_1.2") to specifically match a versioned recipe.

#### 4.8.2.2. Other Variables Related to Commercial Licenses[¶][37]

Other helpful variables related to commercial license handling exist and are defined in the `poky/meta/conf/distro/include/default-distrovars.inc` file:

```
     COMMERCIAL_AUDIO_PLUGINS ?= ""
     COMMERCIAL_VIDEO_PLUGINS ?= ""

```

If you want to enable these components, you can do so by making sure you have statements similar to the following in your `local.conf` configuration file:

```
     COMMERCIAL_AUDIO_PLUGINS = "gst-plugins-ugly-mad \
        gst-plugins-ugly-mpegaudioparse"
     COMMERCIAL_VIDEO_PLUGINS = "gst-plugins-ugly-mpeg2dec \
        gst-plugins-ugly-mpegstream gst-plugins-bad-mpegvideoparse"
     LICENSE_FLAGS_WHITELIST = "commercial_gst-plugins-ugly commercial_gst-plugins-bad commercial_qmmp"

```

Of course, you could also create a matching whitelist for those components using the more general "commercial" in the whitelist, but that would also enable all the other packages with [`LICENSE_FLAGS`][3477] containing "commercial", which you may or may not want:

```
     LICENSE_FLAGS_WHITELIST = "commercial"

```

Specifying audio and video plug-ins as part of the `COMMERCIAL_AUDIO_PLUGINS` and `COMMERCIAL_VIDEO_PLUGINS` statements (along with the enabling`LICENSE_FLAGS_WHITELIST`) includes the plug-ins or components into built images, thus adding support for media formats or components.
